# ğŸš€ IntelliNeuro PerceptronX
https://pypi.org/project/IntelliNeuro/0.1.0/

## ğŸ¤– Custom Perceptron Machine Learning Library

**Author:** Ajay Soni  
**Version:** 0.1.0  
**Repository:** https://github.com/ml-beginner-learner/IntelliNeuro  

---

## ğŸ“š Introduction

**IntelliNeuroâ€™s PerceptronX** is a modular and fully custom-built **Perceptron-based Machine Learning library**, developed from scratch using only **NumPy** and **pandas** for efficient matrix operations and data handling. Itâ€™s crafted to give learners and developers a transparent view of how fundamental neural architectures and gradient-based optimizations work internally.

This library supports multiple tasks:
- ğŸ”¹ Linear regression (continuous value prediction)
- ğŸ”¹ Binary classification using sigmoid activation
- ğŸ”¹ Experimental multi-class classification via softmax activation

Designed for clarity and extensibility, **PerceptronX** is ideal for those wanting to *learn, modify, and visualize* how perceptrons evolve through gradient descent and backpropagation in a minimal yet educational setup.

---

## âœ¨ Key Features

### ğŸ¯ Versatile Learning Capabilities
- Perform **linear regression**, **binary**, and **multi-class classification** from the same unified API.
- Automatically detects the task type based on target variable shape.

### âš™ï¸ Smart Preprocessing Tools
- Built-in **scaling options**: `'none'`, `'minmax'`, `'standard'`
- Manual implementation of normalization and standardization for full transparency.
- Built-in **validation checks** to prevent data mismatch or improper scaling.

### âš¡ Optimized Training Loop
- Implements **stochastic gradient descent** with up to **2.5 million iterations**.
- Supports **early stopping** based on tolerance and convergence.
- Configurable **learning rate, validation split, and tolerance levels**.
- Verbose training output includes iteration progress, current loss, and convergence messages.

### ğŸ“Š Prediction & Evaluation
- Predicts using fitted weights and bias for all supported tasks.
- Offers an **evaluation module** including:
  - **Regression Metrics:** MSE, RMSE, RMSLE
  - **Binary Metrics:** Accuracy, Precision, Recall, F1
  - **Multi-class Metrics:** Weighted Accuracy, Precision, Recall, F1
- Built-in scoring wrapper simplifies evaluation for both beginners and pros.

### ğŸ¨ Developer-Friendly Output
- Uses **colorama** for color-coded terminal logs:
  - ğŸŸ¢ Success
  - ğŸŸ¡ Warning
  - ğŸ”´ Error
- Provides rich textual feedback on training state and potential improvements.

---

## ğŸš€ Quickstart Guide

### 1ï¸âƒ£ Install the package
```bash
pip install IntelliNeuro==0.1.0
```

### 2ï¸âƒ£ Import and initialize
```python
from PerceptronX import Perceptron

model = Perceptron(
    learning_rate=0.001,
    validation_split=0.2,
    scaling='standard',
    is_scaled=False,
    tolerance=1e-6
)
```

### 3ï¸âƒ£ Train the model
```python
model.fit(X_train, y_train)
```

### 4ï¸âƒ£ Predict
```python
predictions = model.predict(X_test)
```

### 5ï¸âƒ£ Evaluate
```python
score = model.score(X_test, y_test, metrics='accuracy')
print(f"Model Accuracy: {score}")
```

---

## ğŸ” How It Works (Under the Hood)

### âš™ï¸ Gradient Descent Core
The perceptron updates its weights iteratively:

\[ w_{new} = w_{old} - \alpha * \nabla J(w) \]

Where:
- **\( \alpha \)** â†’ learning rate
- **\( J(w) \)** â†’ loss function (depends on task)

Each iteration minimizes:
- **Linear regression:** Mean Squared Error (MSE)
- **Binary classification:** Binary Cross-Entropy
- **Multi-class classification:** Categorical Cross-Entropy

### ğŸ§© Scaling Options
- **MinMaxScaler:** `(X - X_min) / (X_max - X_min)`
- **StandardScaler:** `(X - mean) / std`
- Optional manual toggling via `is_scaled` flag for user control.

### ğŸ§ª Validation Split
Automatically separates validation data (based on `validation_split`), trains on the rest, and prints validation accuracy/loss after training.

### ğŸ”” Activation Functions
- **Sigmoid:** For binary outputs
- **Softmax:** For multi-class tasks

### ğŸ§® Weight Initialization
- Random normal initialization for weights.
- Zero initialization for bias.

---

## âš ï¸ Important Usage Notes

- Multi-class classification is still **experimental**, designed for demonstration and learning.
- Ensure **proper data scaling** before training â€” incorrect scaling may slow convergence.
- Calling `predict()` before `fit()` will raise an error.
- Verbose logs can be toggled off if preferred for performance runs.

---

## ğŸ›  Installation Requirements

### Dependencies
```bash
pip install numpy pandas scikit-learn colorama
```

### Minimum Requirements
- Python 3.7+
- CPU: Any modern processor
- RAM: 4GB or above recommended

---

## ğŸ’¡ Best Practices

âœ… Always inspect your dataset with summary statistics before training.  
âœ… Use standard scaling for models with large feature ranges.  
âœ… Adjust learning rate carefully; small rates improve stability.  
âœ… Observe tolerance-based convergence messages to avoid overfitting.  
âœ… Multi-class should be used for educational visualization, not production.  

---

## ğŸ§  Educational Focus

**IntelliNeuro PerceptronX** isnâ€™t just a library â€” itâ€™s a *learning tool.*  
Each method is structured to demonstrate how the perceptron learns step-by-step, allowing developers to visualize how gradient descent evolves weight matrices.

This makes it a perfect resource for:
- Students exploring machine learning fundamentals.
- Educators building course materials.
- Researchers prototyping perceptron logic for custom frameworks.

---

## ğŸ¤ Support & Contributions

**Author:** Ajay Soni  
**Email:** programmingwithcode@gmail.com  
**Repository:** https://github.com/ml-beginner-learner/IntelliNeuro

Contributions are always welcome â€” whether through bug reports, performance suggestions, or new features!  
Please fork the repo and submit a pull request.

---

## ğŸ“„ License

Licensed under the **MIT License** â€” feel free to modify, distribute, and enhance the code with proper credit.

---

## â­ Closing Note

If you found **IntelliNeuro PerceptronX** useful or insightful, donâ€™t forget to leave a **â­ on GitHub** and share it with your developer peers. Together, we build open and transparent ML tools for the next generation.
